{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kathi\\Anaconda3\\envs\\python_2.7_environment\\lib\\site-packages\\pydub\\utils.py:174: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import sklearn.cluster\n",
    "import time\n",
    "import scipy\n",
    "import os\n",
    "import pyAudioAnalysis\n",
    "import pyAudioAnalysis.audioFeatureExtraction as aF\n",
    "import pyAudioAnalysis.audioTrainTest as aT\n",
    "import pyAudioAnalysis.audioBasicIO\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import sklearn.discriminant_analysis\n",
    "import csv\n",
    "import os.path\n",
    "import sklearn\n",
    "import sklearn.cluster\n",
    "import hmmlearn.hmm\n",
    "import cPickle\n",
    "import glob\n",
    "import pyaudio\n",
    "import wave \n",
    "import Tkinter as tk\n",
    "import time\n",
    "import ttk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainHMM_computeStatistics(features, labels):\n",
    "    '''\n",
    "    This function computes the statistics used to train an HMM joint segmentation-classification model\n",
    "    using a sequence of sequential features and respective labels\n",
    "\n",
    "    ARGUMENTS:\n",
    "     - features:    a numpy matrix of feature vectors (numOfDimensions x numOfWindows)\n",
    "     - labels:    a numpy array of class indices (numOfWindows x 1)\n",
    "    RETURNS:\n",
    "     - startprob:    matrix of prior class probabilities (numOfClasses x 1)\n",
    "     - transmat:    transition matrix (numOfClasses x numOfClasses)\n",
    "     - means:    means matrix (numOfDimensions x 1)\n",
    "     - cov:        deviation matrix (numOfDimensions x 1)\n",
    "    '''\n",
    "    uLabels = numpy.unique(labels)\n",
    "    nComps = len(uLabels)\n",
    "\n",
    "    nFeatures = features.shape[0]\n",
    "\n",
    "    if features.shape[1] < labels.shape[0]:\n",
    "        print \"trainHMM warning: number of short-term feature vectors must be greater or equal to the labels length!\"\n",
    "        labels = labels[0:features.shape[1]]\n",
    "\n",
    "    # compute prior probabilities:\n",
    "    startprob = numpy.zeros((nComps,))\n",
    "    for i, u in enumerate(uLabels):\n",
    "        startprob[i] = numpy.count_nonzero(labels == u)\n",
    "    startprob = startprob / startprob.sum()                # normalize prior probabilities\n",
    "\n",
    "    # compute transition matrix:\n",
    "    transmat = numpy.zeros((nComps, nComps))\n",
    "    for i in range(labels.shape[0]-1):\n",
    "        transmat[int(labels[i]), int(labels[i + 1])] += 1\n",
    "    for i in range(nComps):                     # normalize rows of transition matrix:\n",
    "        transmat[i, :] /= transmat[i, :].sum()\n",
    "\n",
    "    means = numpy.zeros((nComps, nFeatures))\n",
    "    for i in range(nComps):\n",
    "        means[i, :] = numpy.matrix(features[:, numpy.nonzero(labels == uLabels[i])[0]].mean(axis=1))\n",
    "\n",
    "    cov = numpy.zeros((nComps, nFeatures))\n",
    "    for i in range(nComps):\n",
    "        #cov[i,:,:] = numpy.cov(features[:,numpy.nonzero(labels==uLabels[i])[0]])  # use this lines if HMM using full gaussian distributions are to be used!\n",
    "        cov[i, :] = numpy.std(features[:, numpy.nonzero(labels == uLabels[i])[0]], axis=1)\n",
    "\n",
    "    return startprob, transmat, means, cov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def speakerDiarization(fileName, numOfSpeakers, mtSize=2.0, mtStep=0.2, stWin=0.05, LDAdim=35, PLOT=False):\n",
    "def speakerDiarization(fileName, numOfSpeakers, mtSize=2.0, mtStep=0.2, stWin=0.05, LDAdim=0, PLOT=False):\n",
    "    '''\n",
    "    ARGUMENTS:\n",
    "        - fileName:        the name of the WAV file to be analyzed\n",
    "        - numOfSpeakers    the number of speakers (clusters) in the recording (<=0 for unknown)\n",
    "        - mtSize (opt)     mid-term window size\n",
    "        - mtStep (opt)     mid-term window step\n",
    "        - stWin  (opt)     short-term window size\n",
    "        - LDAdim (opt)     LDA dimension (0 for no LDA)\n",
    "        - PLOT     (opt)   0 for not plotting the results 1 for plottingy\n",
    "    '''\n",
    "    [Fs, x] = pyAudioAnalysis.audioBasicIO.readAudioFile(fileName)\n",
    "    x = pyAudioAnalysis.audioBasicIO.stereo2mono(x)\n",
    "    Duration = len(x) / Fs\n",
    "\n",
    "    #[Classifier1, MEAN1, STD1, classNames1, mtWin1, mtStep1, stWin1, stStep1, computeBEAT1] = aT.loadKNNModel(os.path.join(\"data\",\"knnSpeakerAll\"))\n",
    "    #[Classifier2, MEAN2, STD2, classNames2, mtWin2, mtStep2, stWin2, stStep2, computeBEAT2] = aT.loadKNNModel(os.path.join(\"data\",\"knnSpeakerFemaleMale\"))\n",
    "    [Classifier1, MEAN1, STD1, classNames1, mtWin1, mtStep1, stWin1, stStep1, computeBEAT1] = aT.loadKNNModel(\"pyAudioAnalysis/data/knnSpeakerAll\")\n",
    "    [Classifier2, MEAN2, STD2, classNames2, mtWin2, mtStep2, stWin2, stStep2, computeBEAT2] = aT.loadKNNModel(\"pyAudioAnalysis/data/knnSpeakerFemaleMale\")\n",
    "\n",
    "    [MidTermFeatures, ShortTermFeatures] = aF.mtFeatureExtraction(x, Fs, mtSize * Fs, mtStep * Fs, round(Fs * stWin), round(Fs*stWin * 0.5))\n",
    "\n",
    "    MidTermFeatures2 = numpy.zeros((MidTermFeatures.shape[0] + len(classNames1) + len(classNames2), MidTermFeatures.shape[1]))\n",
    "\n",
    "    for i in range(MidTermFeatures.shape[1]):\n",
    "        curF1 = (MidTermFeatures[:, i] - MEAN1) / STD1\n",
    "        curF2 = (MidTermFeatures[:, i] - MEAN2) / STD2\n",
    "        [Result, P1] = aT.classifierWrapper(Classifier1, \"knn\", curF1)\n",
    "        [Result, P2] = aT.classifierWrapper(Classifier2, \"knn\", curF2)\n",
    "        MidTermFeatures2[0:MidTermFeatures.shape[0], i] = MidTermFeatures[:, i]\n",
    "        MidTermFeatures2[MidTermFeatures.shape[0]:MidTermFeatures.shape[0]+len(classNames1), i] = P1 + 0.0001\n",
    "        MidTermFeatures2[MidTermFeatures.shape[0] + len(classNames1)::, i] = P2 + 0.0001\n",
    "\n",
    "    MidTermFeatures = MidTermFeatures2    # TODO\n",
    "    # SELECT FEATURES:\n",
    "    #iFeaturesSelect = [8,9,10,11,12,13,14,15,16,17,18,19,20];                                                                                         # SET 0A\n",
    "    #iFeaturesSelect = [8,9,10,11,12,13,14,15,16,17,18,19,20, 99,100];                                                                                 # SET 0B\n",
    "    #iFeaturesSelect = [8,9,10,11,12,13,14,15,16,17,18,19,20, 68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,\n",
    "    #   97,98, 99,100];     # SET 0C\n",
    "\n",
    "    iFeaturesSelect = [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53]                           # SET 1A\n",
    "    #iFeaturesSelect = [8,9,10,11,12,13,14,15,16,17,18,19,20,41,42,43,44,45,46,47,48,49,50,51,52,53, 99,100];                                          # SET 1B\n",
    "    #iFeaturesSelect = [8,9,10,11,12,13,14,15,16,17,18,19,20,41,42,43,44,45,46,47,48,49,50,51,52,53, 68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98, 99,100];     # SET 1C\n",
    "\n",
    "    #iFeaturesSelect = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53];             # SET 2A\n",
    "    #iFeaturesSelect = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53, 99,100];     # SET 2B\n",
    "    #iFeaturesSelect = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53, 68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98, 99,100];     # SET 2C\n",
    "\n",
    "    #iFeaturesSelect = range(100);                                                                                                    # SET 3\n",
    "    #MidTermFeatures += numpy.random.rand(MidTermFeatures.shape[0], MidTermFeatures.shape[1]) * 0.000000010\n",
    "\n",
    "    MidTermFeatures = MidTermFeatures[iFeaturesSelect, :]\n",
    "\n",
    "    (MidTermFeaturesNorm, MEAN, STD) = aT.normalizeFeatures([MidTermFeatures.T])\n",
    "    MidTermFeaturesNorm = MidTermFeaturesNorm[0].T\n",
    "    numOfWindows = MidTermFeatures.shape[1]\n",
    "\n",
    "    # remove outliers:\n",
    "    DistancesAll = numpy.sum(distance.squareform(distance.pdist(MidTermFeaturesNorm.T)), axis=0)\n",
    "    MDistancesAll = numpy.mean(DistancesAll)\n",
    "    iNonOutLiers = numpy.nonzero(DistancesAll < 1.2 * MDistancesAll)[0]\n",
    "\n",
    "    # TODO: Combine energy threshold for outlier removal:\n",
    "    #EnergyMin = numpy.min(MidTermFeatures[1,:])\n",
    "    #EnergyMean = numpy.mean(MidTermFeatures[1,:])\n",
    "    #Thres = (1.5*EnergyMin + 0.5*EnergyMean) / 2.0\n",
    "    #iNonOutLiers = numpy.nonzero(MidTermFeatures[1,:] > Thres)[0]\n",
    "    #print iNonOutLiers\n",
    "\n",
    "    perOutLier = (100.0 * (numOfWindows - iNonOutLiers.shape[0])) / numOfWindows\n",
    "    MidTermFeaturesNormOr = MidTermFeaturesNorm\n",
    "    MidTermFeaturesNorm = MidTermFeaturesNorm[:, iNonOutLiers]\n",
    "\n",
    "    # LDA dimensionality reduction:\n",
    "    if LDAdim > 0:\n",
    "        #[mtFeaturesToReduce, _] = aF.mtFeatureExtraction(x, Fs, mtSize * Fs, stWin * Fs, round(Fs*stWin), round(Fs*stWin));\n",
    "        # extract mid-term features with minimum step:\n",
    "        mtWinRatio = int(round(mtSize / stWin))\n",
    "        mtStepRatio = int(round(stWin / stWin))\n",
    "        mtFeaturesToReduce = []\n",
    "        numOfFeatures = len(ShortTermFeatures)\n",
    "        numOfStatistics = 2\n",
    "        #for i in range(numOfStatistics * numOfFeatures + 1):\n",
    "        for i in range(numOfStatistics * numOfFeatures):\n",
    "            mtFeaturesToReduce.append([])\n",
    "\n",
    "        for i in range(numOfFeatures):        # for each of the short-term features:\n",
    "            curPos = 0\n",
    "            N = len(ShortTermFeatures[i])\n",
    "            while (curPos < N):\n",
    "                N1 = curPos\n",
    "                N2 = curPos + mtWinRatio\n",
    "                if N2 > N:\n",
    "                    N2 = N\n",
    "                curStFeatures = ShortTermFeatures[i][N1:N2]\n",
    "                mtFeaturesToReduce[i].append(numpy.mean(curStFeatures))\n",
    "                mtFeaturesToReduce[i+numOfFeatures].append(numpy.std(curStFeatures))\n",
    "                curPos += mtStepRatio\n",
    "        mtFeaturesToReduce = numpy.array(mtFeaturesToReduce)\n",
    "        mtFeaturesToReduce2 = numpy.zeros((mtFeaturesToReduce.shape[0] + len(classNames1) + len(classNames2), mtFeaturesToReduce.shape[1]))\n",
    "        for i in range(mtFeaturesToReduce.shape[1]):\n",
    "            curF1 = (mtFeaturesToReduce[:, i] - MEAN1) / STD1\n",
    "            curF2 = (mtFeaturesToReduce[:, i] - MEAN2) / STD2\n",
    "            [Result, P1] = aT.classifierWrapper(Classifier1, \"knn\", curF1)\n",
    "            [Result, P2] = aT.classifierWrapper(Classifier2, \"knn\", curF2)\n",
    "            mtFeaturesToReduce2[0:mtFeaturesToReduce.shape[0], i] = mtFeaturesToReduce[:, i]\n",
    "            mtFeaturesToReduce2[mtFeaturesToReduce.shape[0]:mtFeaturesToReduce.shape[0] + len(classNames1), i] = P1 + 0.0001\n",
    "            mtFeaturesToReduce2[mtFeaturesToReduce.shape[0]+len(classNames1)::, i] = P2 + 0.0001\n",
    "        mtFeaturesToReduce = mtFeaturesToReduce2\n",
    "        mtFeaturesToReduce = mtFeaturesToReduce[iFeaturesSelect, :]\n",
    "        #mtFeaturesToReduce += numpy.random.rand(mtFeaturesToReduce.shape[0], mtFeaturesToReduce.shape[1]) * 0.0000010\n",
    "        (mtFeaturesToReduce, MEAN, STD) = aT.normalizeFeatures([mtFeaturesToReduce.T])\n",
    "        mtFeaturesToReduce = mtFeaturesToReduce[0].T\n",
    "        #DistancesAll = numpy.sum(distance.squareform(distance.pdist(mtFeaturesToReduce.T)), axis=0)\n",
    "        #MDistancesAll = numpy.mean(DistancesAll)\n",
    "        #iNonOutLiers2 = numpy.nonzero(DistancesAll < 3.0*MDistancesAll)[0]\n",
    "        #mtFeaturesToReduce = mtFeaturesToReduce[:, iNonOutLiers2]\n",
    "        Labels = numpy.zeros((mtFeaturesToReduce.shape[1], ));\n",
    "        LDAstep = 1.0\n",
    "        LDAstepRatio = LDAstep / stWin\n",
    "        #print LDAstep, LDAstepRatio\n",
    "        for i in range(Labels.shape[0]):\n",
    "            Labels[i] = int(i*stWin/LDAstepRatio);        \n",
    "        clf = sklearn.discriminant_analysis.LinearDiscriminantAnalysis(n_components=LDAdim)\n",
    "        clf.fit(mtFeaturesToReduce.T, Labels)\n",
    "        MidTermFeaturesNorm = (clf.transform(MidTermFeaturesNorm.T)).T\n",
    "\n",
    "    if numOfSpeakers <= 0:\n",
    "        sRange = range(2, 10)\n",
    "    else:\n",
    "        sRange = [numOfSpeakers]\n",
    "    clsAll = []\n",
    "    silAll = []\n",
    "    centersAll = []\n",
    "    \n",
    "    for iSpeakers in sRange:        \n",
    "        k_means = sklearn.cluster.KMeans(n_clusters = iSpeakers)\n",
    "        k_means.fit(MidTermFeaturesNorm.T)\n",
    "        cls = k_means.labels_        \n",
    "        means = k_means.cluster_centers_\n",
    "\n",
    "        # Y = distance.squareform(distance.pdist(MidTermFeaturesNorm.T))\n",
    "        clsAll.append(cls)\n",
    "        centersAll.append(means)\n",
    "        silA = []; silB = []\n",
    "        for c in range(iSpeakers):                                # for each speaker (i.e. for each extracted cluster)\n",
    "            clusterPerCent = numpy.nonzero(cls==c)[0].shape[0] / float(len(cls))\n",
    "            if clusterPerCent < 0.020:\n",
    "                silA.append(0.0)\n",
    "                silB.append(0.0)\n",
    "            else:\n",
    "                MidTermFeaturesNormTemp = MidTermFeaturesNorm[:,cls==c]            # get subset of feature vectors\n",
    "                Yt = distance.pdist(MidTermFeaturesNormTemp.T)                # compute average distance between samples that belong to the cluster (a values)\n",
    "                silA.append(numpy.mean(Yt)*clusterPerCent)\n",
    "                silBs = []\n",
    "                for c2 in range(iSpeakers):                        # compute distances from samples of other clusters\n",
    "                    if c2!=c:\n",
    "                        clusterPerCent2 = numpy.nonzero(cls==c2)[0].shape[0] / float(len(cls))\n",
    "                        MidTermFeaturesNormTemp2 = MidTermFeaturesNorm[:,cls==c2]\n",
    "                        Yt = distance.cdist(MidTermFeaturesNormTemp.T, MidTermFeaturesNormTemp2.T)\n",
    "                        silBs.append(numpy.mean(Yt)*(clusterPerCent+clusterPerCent2)/2.0)\n",
    "                silBs = numpy.array(silBs)                            \n",
    "                silB.append(min(silBs))                            # ... and keep the minimum value (i.e. the distance from the \"nearest\" cluster)\n",
    "        silA = numpy.array(silA); \n",
    "        silB = numpy.array(silB); \n",
    "        sil = []\n",
    "        for c in range(iSpeakers):                                # for each cluster (speaker)\n",
    "            sil.append( ( silB[c] - silA[c]) / (max(silB[c],  silA[c])+0.00001)  )        # compute silhouette\n",
    "\n",
    "        silAll.append(numpy.mean(sil))                                # keep the AVERAGE SILLOUETTE\n",
    "\n",
    "    #silAll = silAll * (1.0/(numpy.power(numpy.array(sRange),0.5)))\n",
    "    imax = numpy.argmax(silAll)                                    # position of the maximum sillouette value\n",
    "    nSpeakersFinal = sRange[imax]                                    # optimal number of clusters\n",
    "\n",
    "    # generate the final set of cluster labels\n",
    "    # (important: need to retrieve the outlier windows: this is achieved by giving them the value of their nearest non-outlier window)\n",
    "    cls = numpy.zeros((numOfWindows,))\n",
    "    for i in range(numOfWindows):\n",
    "        j = numpy.argmin(numpy.abs(i-iNonOutLiers))        \n",
    "        cls[i] = clsAll[imax][j]\n",
    "        \n",
    "    # Post-process method 1: hmm smoothing\n",
    "    for i in range(1):\n",
    "        startprob, transmat, means, cov = trainHMM_computeStatistics(MidTermFeaturesNormOr, cls)\n",
    "        hmm = hmmlearn.hmm.GaussianHMM(startprob.shape[0], \"diag\")            # hmm training        \n",
    "        hmm.startprob_ = startprob\n",
    "        hmm.transmat_ = transmat            \n",
    "        hmm.means_ = means; hmm.covars_ = cov\n",
    "        cls = hmm.predict(MidTermFeaturesNormOr.T)                    \n",
    "    \n",
    "    # Post-process method 2: median filtering:\n",
    "    cls = scipy.signal.medfilt(cls, 13)\n",
    "    cls = scipy.signal.medfilt(cls, 11)\n",
    "\n",
    "    sil = silAll[imax]                                        # final sillouette\n",
    "    classNames = [\"speaker{0:d}\".format(c) for c in range(nSpeakersFinal)];\n",
    "\n",
    "\n",
    "    # load ground-truth if available\n",
    "    gtFile = fileName.replace('.wav', '.segments');                            # open for annotated file\n",
    "    if os.path.isfile(gtFile):                                    # if groundturh exists\n",
    "        [segStart, segEnd, segLabels] = readSegmentGT(gtFile)                    # read GT data\n",
    "        flagsGT, classNamesGT = segs2flags(segStart, segEnd, segLabels, mtStep)            # convert to flags\n",
    "\n",
    "    if PLOT:\n",
    "        fig = plt.figure()    \n",
    "        if numOfSpeakers>0:\n",
    "            ax1 = fig.add_subplot(111)\n",
    "        else:\n",
    "            ax1 = fig.add_subplot(211)\n",
    "        ax1.set_yticks(numpy.array(range(len(classNames))))\n",
    "        ax1.axis((0, Duration, -1, len(classNames)))\n",
    "        ax1.set_yticklabels(classNames)\n",
    "        ax1.plot(numpy.array(range(len(cls)))*mtStep+mtStep/2.0, cls)\n",
    "\n",
    "    if os.path.isfile(gtFile):\n",
    "        if PLOT:\n",
    "            ax1.plot(numpy.array(range(len(flagsGT)))*mtStep+mtStep/2.0, flagsGT, 'r')\n",
    "        purityClusterMean, puritySpeakerMean = evaluateSpeakerDiarization(cls, flagsGT)\n",
    "        print \"{0:.1f}\\t{1:.1f}\".format(100*purityClusterMean, 100*puritySpeakerMean)\n",
    "        if PLOT:\n",
    "            plt.title(\"Cluster purity: {0:.1f}% - Speaker purity: {1:.1f}%\".format(100*purityClusterMean, 100*puritySpeakerMean) )\n",
    "    if PLOT:\n",
    "        plt.xlabel(\"time (seconds)\")\n",
    "        #print sRange, silAll    \n",
    "        if numOfSpeakers<=0:\n",
    "            plt.subplot(212)\n",
    "            plt.plot(sRange, silAll)\n",
    "            plt.xlabel(\"number of clusters\");\n",
    "            plt.ylabel(\"average clustering's sillouette\");\n",
    "        plt.show()\n",
    "    return cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input_path = \"C:/DiesUndDas/Programmierkram/Python/roboy/roboytestfiles/two_talking/two_talking_after_another_channel_1.wav\"\n",
    "#input_path = \"C:/DiesUndDas/Programmierkram/Python/roboy/roboytestfiles/random_internet_dialog_channel_1.wav\"\n",
    "#input_path = \"C:/Users/kathi/Documents/4.Semester/roboy/mic_0_two_people.wav\"\n",
    "#input_path = \"C:/Users/kathi/Documents/4.Semester/roboy/anne_karin_.wav\"  \n",
    "#input_path = \"C:/Users/kathi/Documents/4.Semester/roboy/sgdialog1.wav\"\n",
    "#input_path = \"C:/Users/kathi/Documents/4.Semester/roboy/two_women.wav\"\n",
    "input_path = \"C:/Users/kathi/Documents/4.Semester/roboy/demo.wav\"\n",
    "\n",
    "\n",
    "\n",
    "#def speakerDiarization(fileName, numOfSpeakers, mtSize=2.0, mtStep=0.2, stWin=0.05, LDAdim=35, PLOT=False):\n",
    "result = speakerDiarization(input_path, 2)\n",
    "\n",
    "#result is an array, were each entry represent who is speaking in the current 200ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def try_sound(chunk,array,label_speaker1,label_speaker2):\n",
    "    '''function to update gui window and play the wav file \n",
    "    '''\n",
    "    data = f.readframes(chunk)  #####????????????????????????\n",
    "    #count=0\n",
    "    start_time = time.time()\n",
    "    index_array=0\n",
    "    while(data):\n",
    "        #data = f.readframes(chunk)  \n",
    "        stream.write(data)\n",
    "        #label_speaker1.after(200, which_speaker,data,chunk,f)\n",
    "        #try:\n",
    "        time_diff=abs(start_time-time.time()) #calculate duration of while loop iteration\n",
    "        if time_diff>=0.2*(index_array+1):# an richtiger stelle im array nachschauen ->\n",
    "            if array[index_array]==0:\n",
    "                label_speaker1.config(fg=\"red\")\n",
    "                #label_speaker1.set(label_speaker.get().upper())\n",
    "                label_speaker2.config(fg=\"grey\")\n",
    "               # print 'speaker 1'\n",
    "                top.update()\n",
    "            elif array[index_array]==1:\n",
    "                label_speaker1.config(fg=\"grey\")\n",
    "                label_speaker2.config(fg=\"red\")\n",
    "               # print 'speaker 2'\n",
    "                top.update()\n",
    "            else:\n",
    "                print 'something weird is happening'\n",
    "            \n",
    "            progress['value']=(float(600)/(float(len(array))))*(float(index_array))\n",
    "            #print (float(array.size)/float(600))*(100*index_array)\n",
    "            top.update_idletasks()\n",
    "            index_array+=1\n",
    "\n",
    "        #count += 1\n",
    "        #except:\n",
    "         #   print'input array too short for auudio stream'\n",
    "            \n",
    "        #time.sleep(5)\n",
    "        data = f.readframes(chunk) \n",
    "        \n",
    "    #progress.stop()    \n",
    "    #stop stream  \n",
    "    stream.stop_stream()  \n",
    "    stream.close()  \n",
    "\n",
    "    #close PyAudio  \n",
    "    p.terminate() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TclError",
     "evalue": "invalid command name \".183457160L.184522376L\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTclError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-2d1721b1ecea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;31m#panel.pack(side = \"bottom\", fill = \"both\", expand = \"yes\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m \u001b[0mtry_sound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel_speaker1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel_speaker2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-ed89a6d93523>\u001b[0m in \u001b[0;36mtry_sound\u001b[1;34m(chunk, array, label_speaker1, label_speaker2)\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[1;32mprint\u001b[0m \u001b[1;34m'something weird is happening'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[0mprogress\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m             \u001b[1;31m#print (float(array.size)/float(600))*(100*index_array)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mtop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_idletasks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kathi\\Anaconda3\\envs\\python_2.7_environment\\lib\\lib-tk\\Tkinter.pyc\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   1335\u001b[0m     \u001b[0m__getitem__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcget\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1337\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1338\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Tkinter objects don't support 'in' tests.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kathi\\Anaconda3\\envs\\python_2.7_environment\\lib\\lib-tk\\Tkinter.pyc\u001b[0m in \u001b[0;36mconfigure\u001b[1;34m(self, cnf, **kw)\u001b[0m\n\u001b[0;32m   1328\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0mallowed\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mcall\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m         \"\"\"\n\u001b[1;32m-> 1330\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_configure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'configure'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1331\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfigure\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1332\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kathi\\Anaconda3\\envs\\python_2.7_environment\\lib\\lib-tk\\Tkinter.pyc\u001b[0m in \u001b[0;36m_configure\u001b[1;34m(self, cmd, cnf, kw)\u001b[0m\n\u001b[0;32m   1319\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mStringType\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getconfigure1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_flatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcnf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_flatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;31m# These used to be defined in Widget:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTclError\u001b[0m: invalid command name \".183457160L.184522376L\""
     ]
    }
   ],
   "source": [
    "#define stream chunk   \n",
    "chunk = 2000  \n",
    "\n",
    "#open a wav format music  \n",
    "#f = wave.open(\"C:/Users/kathi/Documents/4.Semester/roboy/mic_0_two_people.wav\",\"rb\")  \n",
    "#f = wave.open(\"C:/Users/kathi/Documents/4.Semester/roboy/anne_karin_.wav\",\"rb\") \n",
    "#f = wave.open(\"C:/Users/kathi/Documents/4.Semester/roboy/sgdialog.wav\",\"rb\")  \n",
    "#f = wave.open(\"C:/Users/kathi/Documents/4.Semester/roboy/two_women.wav\",\"rb\")  \n",
    "f = wave.open(\"C:/Users/kathi/Documents/4.Semester/roboy/demo.wav\",\"rb\")  \n",
    "\n",
    "\n",
    "#instantiate PyAudio  \n",
    "p = pyaudio.PyAudio()  \n",
    "#open stream  \n",
    "stream = p.open(format = p.get_format_from_width(f.getsampwidth()),  \n",
    "                channels = f.getnchannels(),  \n",
    "                rate = f.getframerate(),  \n",
    "                output = True)  \n",
    "#read data  \n",
    "data = f.readframes(chunk)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######creating gui window here \n",
    "\n",
    "top = tk.Toplevel()\n",
    "\n",
    "top.title(\"Who is speaking?\")\n",
    "#top.configure(background='black')\n",
    "frame = tk.Frame(top)\n",
    "frame.pack()\n",
    "top.geometry(\"700x300\")\n",
    "top.pack_propagate(0)\n",
    "\n",
    "progress=ttk.Progressbar(top,orient=tk.HORIZONTAL,length=600,maximum=600,mode='determinate')\n",
    "progress.pack()\n",
    "#progress['maximum']=600\n",
    "img=tk.PhotoImage(file=\"roboy.gif\")\n",
    "#img=img.zoom(25)\n",
    "img=img.subsample(2)\n",
    "panel = tk.Label(top, image = img)\n",
    "#panel.pack(side = \"left\")#, fill = \"both\", expand = \"yes\")\n",
    "panel.pack()\n",
    "\n",
    "\n",
    "label_speaker1 = tk.Label(top, fg=\"dark red\")\n",
    "label_speaker1.pack(padx=5, pady=10, side=tk.LEFT)\n",
    "label_speaker1.config(text='speaker 1',width=20)\n",
    "label_speaker1.config(font=(\"Courier\", 20))\n",
    "\n",
    "\n",
    "label_speaker2 = tk.Label(top, fg=\"dark red\")\n",
    "label_speaker2.pack(padx=5, pady=10, side=tk.LEFT)\n",
    "label_speaker2.config(text='speaker 2',width=20)\n",
    "label_speaker2.config(font=(\"Courier\", 20))\n",
    "\n",
    "\n",
    "#img=plt.imread('test.png')\n",
    "#plt.imshow(img)\n",
    "#panel = tk.Label(top, image = img)\n",
    "#panel.pack(side = \"bottom\", fill = \"both\", expand = \"yes\")\n",
    "\n",
    "try_sound(chunk,result,label_speaker1,label_speaker2)\n",
    "top.update()\n",
    "\n",
    "\n",
    "top.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
